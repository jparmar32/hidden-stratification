{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('gas': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b5497fc48e4c5a82379fff9cd7dd3bebcc1f395a507c9c40b1468a53626d3121"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(targets,probs,recall):\n",
    "    diff = 1e10\n",
    "    for thresh in np.arange(0,1,0.001):\n",
    "        recall_ = recall_score(targets,probs>thresh)\n",
    "        if np.abs(recall_-recall) < diff:\n",
    "            best_thresh = thresh\n",
    "            diff = np.abs(recall_-recall)\n",
    "\n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ERM on val\n",
      "\n",
      "Overall F1-score: 60.8 +/- 3.6\n",
      "Robust F1-score: 36.5 +/- 5.8\n",
      "Pmx w/ Tubes F1-score: 63.5 +/- 4.6\n",
      "Pmx w/o Tubes F1-score: 27.3 +/- 6.4\n",
      "\n",
      "====================\n",
      "\n",
      "TRUE_SUBCLASS_GDRO on val\n",
      "\n",
      "Overall F1-score: 57.4 +/- 4.8\n",
      "Robust F1-score: 31.4 +/- 2.7\n",
      "Pmx w/ Tubes F1-score: 58.0 +/- 6.5\n",
      "Pmx w/o Tubes F1-score: 26.7 +/- 4.8\n",
      "\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "modes = [\"erm\",\"true_subclass_gdro\"]\n",
    "seeds = [101,102,103,104,105]\n",
    "split = \"val\"\n",
    "recall = 0.55\n",
    "\n",
    "for mode in modes:\n",
    "    overall_f1s = []\n",
    "    robust_f1s = []\n",
    "    tubes_f1s = []\n",
    "    notubes_f1s = []\n",
    "    for seed in seeds:\n",
    "        result_dir = f\"/media/nvme_data/gas_results/pmx/{mode}/seed_{seed}\"\n",
    "        outputs_dir = os.path.join(result_dir,\"outputs.pt\")\n",
    "\n",
    "        outputs = torch.load(outputs_dir)[split]\n",
    "\n",
    "        probs = outputs[\"probs\"]\n",
    "        targets = outputs[\"targets\"]\n",
    "        subclass_labels = outputs[\"true_subclass\"]\n",
    "\n",
    "        thresh = get_threshold(targets,probs,recall)\n",
    "        preds = probs > thresh\n",
    "        \n",
    "        mask = np.logical_not(subclass_labels)\n",
    "        neg_mask = np.logical_not(targets)\n",
    "        postube_mask = np.logical_and(subclass_labels,targets)\n",
    "        mask1 = np.logical_or(neg_mask,postube_mask)\n",
    "        posnotube_mask = np.logical_and(np.logical_not(subclass_labels),targets) \n",
    "        mask2 = np.logical_or(neg_mask,posnotube_mask)\n",
    "\n",
    "        overall_f1s.append(f1_score(targets,preds))\n",
    "        robust_f1s.append(f1_score(targets[mask], preds[mask]))\n",
    "        tubes_f1s.append(f1_score(targets[mask1], preds[mask1]))\n",
    "        notubes_f1s.append(f1_score(targets[mask2], preds[mask2]))\n",
    "\n",
    "    overall_f1s = np.array(overall_f1s)\n",
    "    robust_f1s = np.array(robust_f1s)\n",
    "    tubes_f1s = np.array(tubes_f1s)\n",
    "    notubes_f1s = np.array(notubes_f1s)\n",
    "\n",
    "    print(f\"\\n{mode.upper()} on {split}\\n\")\n",
    "    print(f\"Overall F1-score: {100*overall_f1s.mean():.1f} +/- {100*1.96*overall_f1s.std()/np.sqrt(len(seeds)):.1f}\")\n",
    "    print(f\"Robust F1-score: {100*robust_f1s.mean():.1f} +/- {100*1.96*robust_f1s.std()/np.sqrt(len(seeds)):.1f}\")\n",
    "    print(f\"Pmx w/ Tubes F1-score: {100*tubes_f1s.mean():.1f} +/- {100*1.96*tubes_f1s.std()/np.sqrt(len(seeds)):.1f}\")\n",
    "    print(f\"Pmx w/o Tubes F1-score: {100*notubes_f1s.mean():.1f} +/- {100*1.96*notubes_f1s.std()/np.sqrt(len(seeds)):.1f}\\n\")\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}